%!TEX TS-program = xelatex
%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass[doublespacing]{bmcart}

%%% Load packages
%\usepackage{amsthm,amsmath}
\RequirePackage{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
\usepackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\def\includegraphic{}
\def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs
\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Application of deep metric learning to molecular graph similarity}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
  addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
  corref={aff1},                       % id of corresponding address, if any
  email={damien.x.coupry@gsk.com}   % email address
]{\inits{D. E.}\fnm{Damien E.} \snm{Coupry}}

\author[
  addressref={aff1},
]{\inits{P.}\fnm{Peter} \snm{Pog\'any}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgdiv{Data and Computational Sciences},             % department, if any
  \orgname{GlaxoSmithKline},          % university, etc
  \city{Stevenage},                              % city
  \cny{UK}                                    % country
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{artnotes}
%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract
Graph based methods are increasingly important in chemistry and drug discovery, with applications ranging from QSAR to molecular generation. Combining graph neural networks and deep metric learning concepts, we expose a framework for quantifying molecular graph similarity based on distance between learned embeddings separate from any endpoint. Using a minimal definition of similarity, and data from the ZINC database of public compounds, this work demonstrate the  properties of the embedding and its suitability for a range of applications, among them a novel reconstruction loss method for training deep molecular auto-encoders. Finally, we compare the applications of the embedding to standard practices, with a focus on known failure points and edge cases; concluding that our approach can be used in conjunction to existing methods.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{metric learning}
\kwd{similarity}
\kwd{graph neural networks}
\kwd{deep learning}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{Introduction}
%   Change 1st sentence: a much used tool -> frequently used
Quantifying the similarity of chemical structures has been frequently used in drug discovery for decades\cite{willett1998chemical}, and has often been adopted as a design principle for lead optimization \cite{kubinyi1998similarity, maggiora2014molecular} under the assumption that similar molecules have a higher probability of exhibiting similar properties than dissimilar ones \cite{johnson1990concepts, patterson1996neighborhood, martin2002structurally}. Indeed, the successful use of bioisosterism in drug development makes heavy use of the concept  \cite{patani1996bioisosterism, lima2005bioisosterism}, to the point that similarity is sometimes defined as a consequence of the properties, rather than the cause\cite{bender2004molecular}. Most of the benchmarks for chemical structure similarity rely on this definition to compare methods \cite{irwin2008community, rohrer2009maximum, riniker2013open}, driven in part by the availability of public activity datasets \cite{gaulton2012chembl}. Yet, pitfalls such as so-called ``activity cliffs''\cite{maggiora2006outliers, stumpfe2012exploring, stumpfe2014recent} should moderate the confidence in the underlying principle. Furthermore, other use cases of similarity exist, and are not captured by the similar properties paradigm: patent mining and infringement prediction \cite{rhodes2007mining}, building block selection for synthesis, retrosynthesis and scaffold hopping\cite{bohm2004scaffold, boehm2008similarity, coley2017computer}, molecular generation evaluation\cite{mendez2020novo}, etc. A ``good'' measure of similarity should ideally show equal performance in all these applications, never relying too much on any one definition or type of benchmark.
%   3rd sentence: Still, these methods ... -> However,
On the practical side, similarity can be more generally understood as the combination of a molecular representation and an appropriate metric\cite{maggiora2014molecular}. Today, the combination of two-dimensional molecular circular fingerprints \cite{cereto2015molecular, rogers2010extended} with the Tanimoto coefficient \cite{bajusz2015tanimoto} is still the most widely used, and  generally hard to outperform in traditional benchmarks\cite{raymond2002effectiveness}. However, these methods suffer from a number of identified drawbacks, regularly analysed but difficult to route around in the absence of a more general representation\cite{flower1998properties, dixon1999hidden}. Most of the recent efforts to develop original molecular encodings focus on the relational nature of molecules as seen in a 2D context. By considering structures as a graph with atoms as nodes and bonds as edges, we can draw on the considerable field of extant work on graph similarity in general: computationally expensive graph edit distance, graph isomorphism quantification or maximum common subgraph \cite{garcia2019ligand, bunke1998graph, bunke1983inexact, dijkman2009graph, berretti2001efficient}, graph kernels for similarity \cite{kriege2020survey}, and the increasingly popular deep learning algorithms\cite{ma2021deep}. The latter rely on embeddings learned from variational reconstruction tasks\cite{jin2018junction}, end-to-end property predictions \cite{brown2009chemoinformatics}. In this work, we leverage  the ability of graph neural networks from the Deep Graph Library\cite{wang2019deep, li2021dgl} to learn chemical structures embeddings using the triplet loss\cite{schultz2004learning}, to our knowledge the first such use of it. 
%   First sentence: a popular architectures -> a popular architecture
This is an application of the deep metric learning approach, a popular architecture from facial recognition \cite{bai2019simgnn}; where a feature space is conditioned with the euclidean distance, making it a metric space suitable for similarity quantification. A training dataset is constructed automatically using a minimal definition of molecular similarity and public compounds. We show that these embeddings satisfy the conditions to be considered an appropriate encoding of molecular graph similarity information, applicable in both traditional benchmarks and novel applications.


\section*{Experiments}
\subsection*{Dataset generation}

% writing out twice the Bemis-Murcko also in front of detailed frame: Bemis-Murcko graph and detailed frames -> Bemis-Murcko graph and Bemis-Murcko detailed frames
% position of whereas changed: Whereas the Bemis-Murcko graph frames contain -> The Bemis-Murcko graph frame contains && The Bemis-Murcko detailed frame -> , whereas the Bemis-Murcko detailed frame
The ZINC database was downloaded (1.487 billion compounds)\cite{ZINC15} and processed as follows. Parent structures were created, bad valencies, compounds with poorly defined bonds, isotope labelled compounds and compounds containing elements other than N, O, C, S, F, Cl, Br and I were removed. This initial filtering removed around 2 million compounds. Reduced Graphs\cite{RedGraph2003,RedGraph2004}, Bemis-Murcko graph and Bemis-Murcko detailed frames\cite{BemisMurcko} were generated for each compound. In the Reduced Graph, the full molecular graph is reduced to pharmacophore feature type nodes. The Bemis-Murcko graph frame contains the anonymous frame of the molecule without the side chains, atom types and bond orders, whereas the Bemis-Murcko detailed frame contains the frame of the molecule (side chains removed) with atom types and bonds marked. Comparison of these molecular representations is given on Figure \ref{fig:GF_DF_RG}.


REOS\cite{Walters1998} and PAINS~A\cite{Baell2010} filters were applied on the remaining compounds and molecular weight (MW) was calculated to remove everything with MW$>$650 daltons, thus keeping 1.199 B compounds. Compounds were clustered in three ways:
\begin{enumerate}
\item Having the same Reduced Graph and Graph Frame (GFRG)
\item Having the same Reduced Graph and Detailed Frame (DFRG)
\item  Having the same Reduced Graph (RG)
\end{enumerate}
% and cluster centers were assigned -> and cluster centeroids were assigned && remaind -> remained
Most of the processing after this was done using BIOVIA Pipeline Pilot\cite{biovia2020}. All compounds belonging to a GFRG cluster with less than 4 members were removed. In the case of compounds belonging to GFRG clusters with more than 10k members, DFRG clusters were used in place of GFRG. For DFRG clusters, a maximum size of 20k members was established, with random subsampling performed on clusters above this limit. 1.13 billion compounds remained and cluster centeroids were assigned to them. Cluster Molecules component of BIOVIA Pipeline Pilot\cite{biovia2020} was used to determine the cluster centroids for each cluster defined above (ECFP4 and heavy atom count was used for getting the centroids). For every cluster the number of identities was calculated. If the number of identities was larger than 0.4, all the cluster elements were discarded. 1.113 billion compounds remained in 16.71 million clusters. The number of clusters for each Reduced Graph was calculated and only Reduced Graphs which have at least 2 clusters were kept (1.059 billion compounds).

% comma before and after conversely. ... is more valuable to the training process. -> ... is more valuable for the training process.
% adding (reference and positive control)
% and it is also more challenging for the training
The triplet loss trains networks by contrasting a reference structure with two additional compounds, called positive and negative controls. The positive control should be qualitatively similar to the reference. For this purpose, the two (reference and positive control) were selected randomly from within the same cluster (GFRG cluster for the initial smaller clusters, for the larger clusters, where GFRF cluster size~$\geq$~10,000, DFRG clusters are used). The negative control should, conversely, be less similar to the reference than the positive. Selecting a very different compound is not optimal, since the chemical space size increases towards larger dissimilarities. Thus, while it would be correct to choose a negative control from a different cluster, choosing a compound that has \textit{some} similar features to the reference is more valuable for the training process and it is also more challenging for the training. Therefore we have randomly selected the negative control from a different cluster than the cluster of the reference, but their Reduced Graph should be the same. This way 12,361,633 triplets were created. A detailed schema of the data preparation can be seen on Figure~\ref{fig:Process_Diagram}.



\subsection*{Model training}

%% The number of used triplets and non-used triplets for the training should be specified!!!: --> To keep ... purposes.

For all training and benchmarking purposes, the random seed is fixed at 42 for repeatability, and the hyperparameters have been kept unoptimized and to the default values to prevent bias. To keep computation times short, only a random sample of 10\% of triplets generated is used during training, the rest being kept for testing purposes. We used the DGL-Lifesci open source framework for computations on graphs, and its message passing neural network implementation (MPNNPredictor)\cite{gilmer2017neural} as model architecture. This type of model repeatedly accumulates bond information as well as node information based on connectivity, and has been used with great effect in state of the art QSAR applications \cite{yang2019analyzing}. We chose to use the default parameters and an output size equal to 16 as an embedding dimension (\textit{n\_tasks}). The input for such a model are molecular graphs, which are obtained using the CanonicalAtomFeaturizer and CanonicalBondFeaturizer from DGL. The details of what is included in the graphs features can be found in the DGL-lifesci documentation. These representations are regularized with a node ablation probability of 1\% and edge ablation probability of 5\%. At each step of the training, an instance of the MPNN is used to embed each of the three graphs of the input (anchor, positive and negative); the triplet margin loss from pytorch\cite{NEURIPS2019_9015} then updates the weights of the network to maximize the distance between the anchor and negative, while minimizing the distance between the anchor and the positive, as seen in Figure~\ref{fig:triplet_arch}.



% adding the github page here
 The training used the pytorch-lightning framework \cite{falcon2019pytorch} with a 25 epochs early stopping criterion, the Adam optimizer with the default learning rate of $10.0^{-3}$, and took two days on an Nvidia GEFORCE1080 GPU with a batch size of 128. For more details, hyperparameters, and training curves, please refer to the project's github page (\href{https://github.com/DCoupry/ChemDist_paper}{https://github.com/DCoupry/ChemDist\_paper}).
 
\subsection*{Benchmarks choice}
The benchmarks for the present use case should optimally measure a number of things:
\begin{itemize}
\item The performance on popular applications; here the activity classification tasks such as the ones described in Riniker \textit{et al}\cite{riniker2013open}.
\item The performance on edge cases, such as the ones described in Flower \textit{et al}\cite{flower1998properties}, particularly when the failure of traditional fingerprint based similarity measure is due to the basic technique of fragmentation.
\item The condition of graph isomorphism: the ordering of the molecule atoms and bonds should have no influence on the embedding.
%\item The information density of the embedding, compared to traditional circular fingerprints
\end{itemize}
Additionally, \textit{desired} properties of an encoding come from the coupling with a metric. In particular, using a euclidean distance metric on a well defined euclidean vector space gives rise to a number of interesting properties:
\begin{itemize}
\item very fast querying and operations
\item Similarity can be defined with respect to geometric elements: around a barycentre, along a path between molecules, within a cone, etc.
\item the space and metric together are unbound in value for dissimilarity: there are many more ways of being dissimilar than similar, and the distances distribution could reflect that.
\end{itemize}
\section*{Results}
\subsection*{Activity prediction tasks benchmarking}
While an imperfect measure of fitness for any new chemical embedding, the dominance of benchmarking platforms making use of a variety of activity prediction datasets makes it an obligatory step in evaluating any new contribution. In particular, it enables two separate conclusions to be reached:
\begin{enumerate}
\item Whether the information contained in the embedding is sufficient to fit models successfully, regardless of compared performance
\item Whether these models are statistically different from references to demonstrate the originality of the embedding
\end{enumerate}

To answer the second query, it is necessary to benchmark models on a suitably high number of instances for each class. For this purpose, a dataset of IC50 activities was extracted from the ChEMBL28 database. All targets with a unique structure count between 5k and 20k were kept, with activity threshold automatically set at the 75th percentile of the PIC50 values if and only if this is superior by at least one standard deviation from the minimum value and maximum value. This classification task was modelled by a k-nearest neighbours classifier from the scikit-learn python package\cite{scikit-learn}, trained on ECFP0 and ECFP4 fingerprints from the rdkit package\cite{LandrumRDKit}, as well as on learned embeddings. Only targets with an ECFP0 5-fold stratified cross validation Cohen's Kappa score above 0.25 were kept, to constrain the benchmark tasks to be relatively hard but tractable, resulting in a set of 55 targets. For each triplet of models, the Cochran's Q test was applied to verify statistical difference. The p-values of 30 tested targets were $<$0.05 and sufficient to reject the null hypothesis that all the models were equivalent. Subsequent confirmation with pairwise McNemar tests with Bonferroni correction show the embedding models to be the source of the statistical difference, thus answering our second point. The performances on this final set of 30 targets are shown in Figure~\ref{fig:Kappa_ChEMBL}: while ranking below ECFP4 in average, the embedding systematically outperforms ECFP0, confirming that the information extracted from the graphs can be used by subsequent algorithms. This answers our first point to our satisfaction. Furthermore, a simple ensembling of models built on ECFP4 and the embedding results in a modest improvement in 15 models, showcasing the potential benefits of integrating our method to existing workflows.



\subsection*{Failure points of circular fingerprints}

% Removing the reference for Figure 6 (this is not figure 6 in this article)
One noted effect of the bit-string fingerprints is the skewing effect of size on the distribution of similarities as illustrated in Figure~6 of Flowers \textit{et al} \cite{flower1998properties}. Applying the same reference set of compounds for comparison on a diverse set of molecules using the MPNN learned embedding leads to a much better shape of the distributions. While the larger molecule has a more chaotic profile of similarity (probably due to the fact that the larger a structure, the more ways for something to be similar to it), it otherwise seems  independent from the size of the molecules. This is shown in Figure~\ref{fig:References_distributions}.




Another point where fingerprints fail to accurately describe molecular similarity is the case of molecules with repeated motifs. When using Tanimoto similarity of circular fingerprints in bit string form, the similarity tapers off quickly to a fixed non-zero value. The learned embedding is immune to this effect. Likewise, the insertion of moieties within a scaffold has an unduly small effect when it does not perturb the fragmentation of the structure by fingerprints, but is correctly shown to matter a lot by the embedding. In addition, it also retains the concepts of fragments, aromaticity, and some level of isosterism. Some examples illustrating these points are shown in Figure~\ref{fig:Similarity_study_cases}.

% Adding more explanation
The usual dissimilarity cutoff values in case of ECFP4 fingerprints are between 0.2-0.4 (anything below this is considered to be similar). At these low values (structures 2 and 3 on Figure~\ref{fig:Similarity_study_cases}) the triplet embedding distance agrees well with ECFP4 dissimilarity.  Structures 6, 9-12, 17 and 20 are largely dissimilar according to ECFP4, having a dissimilarity at least or above 0.8. As we can see the triplet embedding distance discriminates between these structures much more than ECFP4. It prefers generally the aromatic structures with similar arrangements against the aliphatic rings, what is expected from the nature of reduced graphs. The 5-membered aromatic rings (e.g. structure 13-16) are closer based on the triplet embedding to the original Reference than the similarly arranged structures with at least 2 aliphatic rings (structures 9-12). This is not so clear in case of ECFP4, which does not distinguish between structures 9 and 10 (both having and ECFP4 dissimilarity of 0.80, whereas the triplet embedding clearly showing that more aliphatic rings are less similar 42.03 vs. 62.87 for 9 and 10, respectively) and creates a large difference between similar structures 7 and 8 (0.71 vs. 0.50 for ECFP4). The 2nd most dissimilar structure based on ECFP4 is structure 6 (with a large dissimilarity of 0.92), whereas the triplet embedding shows a not too large dissimilarity (12.32). This later is not surprising, although the arrangment of the ring systems is the same and the molecular shape is similar, the non-featurized ECFP4 only understands that the rings changed completely between the reference and structure 6 and it does not find a lot of similarity between the benzene and triazine rings.

To show further differences between the ECFP4 and the triplet embedding a randomly selected set of 100,000 triplets unused in the training process was utilized to calculate  both the ECFP4 dissimilarities and the triplet embedding distances for the positive and negative controls in respect to the reference (anchor). The experiment showed that both ECFP4 dissimilarity and the triplet embedding determined the correct order (positive control has lower distance than the negative) for 89,133 triplets, showing that in most cases both work fine for most of the cases. Not surprisinlgy, ECFP4 failed more often (9911 cases), whereas the triplet embedding failed only for 956 cases. There are 428 cases were both failed. Although this is not a quantitative performance investigation for the two distance metrics, it can give us insight about their weak points. In Figure~\ref{fig:Unseen_Fails} we show 4 examples (the whole list is in the github repository) where one of the descriptors failed to give the correct order. In case of triplet 1), ECFP4 predicted that the neative control (right hand side) is closer to the reference than the positive one (middle). Since in case of the negative control the left hand side of the molecule changes (4-membered ring is changed to a 6-membered ring), for a chemical series point of view this change is larger than the changes in the side chains, which can be seen in case of the positive control.
Triplet 2) shows a similar case, where ECFP4 fails to properly give the order. Here the failure is caused both by feature repetition and a relatively small change of the ring size. In case of the negative control, the piperidine ring appears two times in the molecule. The ECFP4 used here (and in many virtual screening and similarity searching experiments) does not contain feature counts, therefore the sensitivity to feature repetition is low (see Figure~2 in reference~\cite{flower1998properties}). Triplet 3) shows also an example where the ring size changes, but here the ECFP4 dissimilarities are almost identical, although there are not only changes in the side chains, but a linker extension, a ring extension and pyrazole ring is changed to an imidazole ring in case of the negative control. 
A different case is triplet 4), where the triplet embedding failed to properly determine the order. As it can be seen, both negative and positive controls have larger changes, although the two rings on the right hand side are the same for the positive control, their connection is different. The amide bond is reversed in both the positive and negative controls compared with the reference structure, the linker has the same length, but different groups and the left hand side ring system is largely different for both the positive and negative controls. Both ECFP4 and the triplet embedding gave a larger distance for these two structures. The insensitvity on the orientation of the amide groups is a well known issue of the reduced graphs. Triplet 4) can be considered as a bad example, since both for positive and negative control there are large changes in the core of the structure. Large part of those structures where the triplet embedding failed are similar to this, i.e. the positive controls and the negative controls are both in not too close distance to the reference and in some cases they are more similar to each other than to the reference. Preparing better the training set might solve part of the issues, but a small number of ``wrong'' examples might always get into the data set.

\subsection*{Additional properties}
% ECFP4 Tanimoto coefficient -> ECFP4 Tanimoto dissimilarity coefficient && MPNN embedding -> MPNN (triplet) embedding && illustrated in -> illustrated in Figure
As stipulated earlier, the distribution of similarities should be notably different between positive examples and negative examples: the first distribution should show a sharp peak around optimal similarity, and the second should display a long tail representing the many different sources of dissimilarity. After applying both the ECFP4 Tanimoto dissimilarity coefficient comparison and the learned MPNN (triplet) embedding to unseen triplets of our generated dataset, we indeed see such a behaviour illustrated in Figure~\ref{fig:ECFP4_Embedding_triplets}.

Another critical desired property for a novel molecular distance measure is the ability to correctly compare partial and \emph{chemically invalid} molecular graphs and provide gradient information. This leads to the important fact that trained embeddings are essentially derivable reconstruction loss with a quadratic energy surface, with widespread potential applications. For example:
\begin{itemize}
\item Accelerated training of reconstruction based molecular generators such as variational auto-encoders.
\item Additional information in tasks such as missing edge and node prediction.
\item Chemical subspace constraints for conditional molecular generators
\end{itemize}
These tasks are deeply unsuitable to traditional fingerprints or property based similarity : for most of the training process, the molecular graphs on which computation happens are completely invalid, the chemical information on what is a molecule still being accrued. Yet a learned embedding, as is shown in Figure~\ref{fig:Ablations}, is very robust to node and edge deletion, demonstrating a quasi linear distance relationship with the number of deleted elements. This is an exciting property, and we look forward to seeing it explored further.



Finally, a critical property of the embedding is its ability to be used in conjunction with transfer learning\cite{tan2018survey, weiss2016survey}, and be retrained on particular subsets of the chemical space according to tailored similarities obtained from SAR, Molecular Matched Pairs\cite{griffen2011matched}, or a more complex multiple-parameters function. Such a retrained model would retain the general concepts of molecular graph similarity while quickly converging to a more appropriate representation of the problem at hand, thus sparing resources in training and data gathering.

\section*{Conclusions}
We have shown that using the triplet margin loss jointly with molecular graph based deep neural networks trains latent representations that satisfy the many definitions of chemical similarity. A naive example of such an embedding was trained with no hyperparameters optimization on a dataset constructed from public molecules and some basic concepts of graph similarity. This naive example compares acceptably out of the box with the accepted standard of circular fingerprints Tanimoto scores, while possessing many additional properties such as being derivable or retrainable. We believe such properties may be of great use to train reconstruction based molecular generators. 


\begin{backmatter}


\section*{Declarations}
\section*{Availability of data and materials}
All code and data is available on \href{https://github.com/DCoupry/ChemDist_paper}{https://github.com/DCoupry/ChemDist\_paper} under an Apache 2 license (GlaxoSmithKline copyright) and is sufficient to reproduce our conclusions and graphs.

\section*{Acknowledgements}

The authors thanks Darren Green and Kim Branson for their preliminary review; as well as the entire Molecular Design team for their constructive feedback.

\section*{Funding}
Not Applicable

\section*{Competing interests}
The authors declare that they have no competing interests.

\section*{Authors' Contributions}
PP generated all datasets and wrote the paper, DC performed the ML study, the analysis and wrote the paper. All authors read and approved the final manuscript.

\section*{Abbreviations}
\begin{itemize}
    \item QSAR  : Quantitative Structure Activity Relationship
    \item GNN : Graph Neural Network
    \item MPNN : Message Passing Neural Network
    \item RG : Reduced Graph
    \item DF : Detailed Frame
    \item GF : Bemis Murcko Graph
    \item ECFP :  Extended Connectivity Fingerprint
\end{itemize}


\bibliographystyle{spbasic}
\bibliography{chemdist}


\section*{Figures}

\begin{figure}[h!]
\caption{A comparison of the Reduced Graph (RG), Bemis-Murcko graph (GF) and detailed frames (DF) clusters. The numbers after the character show the cluster. RG1 is a cluster of aromatic ring containing compound which contain hydrogen bond donor and acceptor. RG2 are aliphatic rings with hydrogen bond donors, RG3 are aliphatic rings without feature. There are only two graph frame clusters: 5-membered rings (GF1) and 6-membered rings (GF2). Detailed frames are only identical, if the compounds differ in ring substituents connected to rings with single bonds (DF5 and DF7).}
\label{fig:GF_DF_RG}
\end{figure}

\begin{figure}[h!]
\caption{The process diagram of data preparation.}
\label{fig:Process_Diagram}
\end{figure}

\begin{figure}[h!]
\caption{The architecture of the triplet loss embedding during training.}
\label{fig:triplet_arch}
\end{figure}
%
\begin{figure}[h!]
\caption{Performance in activity classification tasks from ChEMBL28.}
\label{fig:Kappa_ChEMBL}
\end{figure}

\begin{figure}[h!]
\caption{Distribution of embedding distances of 5 references compounds to a diverse set of 120k compounds from the Zinc database.}
\label{fig:References_distributions}
\end{figure}


\begin{figure}[h!]
\caption{Selection of pairwise comparisons illustrating a diverse set of molecular similarities.}
\label{fig:Similarity_study_cases}
\end{figure}

\begin{figure}[h!]
\caption{Selection of triplets not seen during the training where ECFP4 and the triplet embedding does not agree in the order of the positive (structure in the middle for each row) and negative (right hand side structure) controls.}
\label{fig:Unseen_Fails}
\end{figure}
%
\begin{figure}[h!]
\caption{Comparison of the similarity distributions on unseen triplets}
\label{fig:ECFP4_Embedding_triplets}
\end{figure}

\begin{figure}[h!]
\caption{Effect of random element deletion on embedding distance. No comparison with ECFP4 could be obtained due to the overwhelming rate of invalidity of the resulting structures.}
\label{fig:Ablations}
\end{figure}

\end{backmatter}
\end{document}
